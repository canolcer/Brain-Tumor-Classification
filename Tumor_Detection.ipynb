{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea472a1-1be1-4255-8704-6cad1c4504f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f441a2c-29cf-476e-b347-d44cf05e8dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path\n",
    "data_dir = 'your_dataset'\n",
    "\n",
    "# Training and testing set paths\n",
    "train_dir = os.path.join(data_dir, 'Training')\n",
    "test_dir = os.path.join(data_dir, 'Testing')\n",
    "\n",
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Loading the dataset and applying data augmentation\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                                  target_size=(224, 224),\n",
    "                                                  batch_size=32,\n",
    "                                                  class_mode='binary')\n",
    "\n",
    "# Model creation\n",
    "base_model = MobileNetV2(weights='imagenet',\n",
    "                         include_top=False,\n",
    "                         input_shape=(224, 224, 3))\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Model compilation\n",
    "model.compile(optimizer=optimizers.Adam(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model training\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=train_generator.samples // 32,\n",
    "                    epochs=10,\n",
    "                    validation_data=test_generator,\n",
    "                    validation_steps=test_generator.samples // 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e01b68a-c9ea-4e56-800c-5d5da5e7d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and test accuracies\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Training and test losses\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Epoch numbers\n",
    "epochs = range(1, len(train_accuracy) + 1)\n",
    "\n",
    "# Accuracy plot\n",
    "plt.plot(epochs, train_accuracy, 'bo', label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Test Accuracy')\n",
    "plt.title('Training and Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Loss plot\n",
    "plt.plot(epochs, train_loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Test Loss')\n",
    "plt.title('Training and Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680db668-cfa4-45f1-8049-c458e99ca5da",
   "metadata": {},
   "source": [
    "1. **Epoch 1:**\n",
    "   - **Training Accuracy:** 94.37%\n",
    "   - **Training Loss:** 0.1607\n",
    "   - **Validation Accuracy:** 58.13%\n",
    "   - **Validation Loss:** 16.0212\n",
    "   - **Comments:** The model starts with relatively high training accuracy but struggles to generalize well on the validation set, indicating potential overfitting.\n",
    "\n",
    "2. **Epoch 2:**\n",
    "   - **Training Accuracy:** 98.15%\n",
    "   - **Training Loss:** 0.0590\n",
    "   - **Validation Accuracy:** 56.88%\n",
    "   - **Validation Loss:** 15.3434\n",
    "   - **Comments:** The training accuracy improves, but the validation accuracy decreases, suggesting that overfitting may still be an issue.\n",
    "\n",
    "3. **Epoch 3:**\n",
    "   - **Training Accuracy:** 98.32%\n",
    "   - **Training Loss:** 0.0439\n",
    "   - **Validation Accuracy:** 58.75%\n",
    "   - **Validation Loss:** 10.3247\n",
    "   - **Comments:** Both training and validation accuracies show improvement, indicating better generalization. However, the validation loss is still relatively high.\n",
    "\n",
    "4. **Epoch 4:**\n",
    "   - **Training Accuracy:** 98.91%\n",
    "   - **Training Loss:** 0.0374\n",
    "   - **Validation Accuracy:** 59.38%\n",
    "   - **Validation Loss:** 9.1711\n",
    "   - **Comments:** Continued improvement in training and validation accuracy, but the validation loss remains elevated.\n",
    "\n",
    "5. **Epoch 5:**\n",
    "   - **Training Accuracy:** 98.99%\n",
    "   - **Training Loss:** 0.0324\n",
    "   - **Validation Accuracy:** 71.25%\n",
    "   - **Validation Loss:** 3.1237\n",
    "   - **Comments:** Significant improvement in validation accuracy, indicating better generalization. The validation loss is also notably reduced.\n",
    "\n",
    "6. **Epoch 6:**\n",
    "   - **Training Accuracy:** 99.41%\n",
    "   - **Training Loss:** 0.0206\n",
    "   - **Validation Accuracy:** 57.50%\n",
    "   - **Validation Loss:** 11.4550\n",
    "   - **Comments:** Training accuracy remains high, but validation accuracy drops, suggesting potential overfitting again.\n",
    "\n",
    "7. **Epoch 7:**\n",
    "   - **Training Accuracy:** 98.03%\n",
    "   - **Training Loss:** 0.0581\n",
    "   - **Validation Accuracy:** 78.75%\n",
    "   - **Validation Loss:** 3.6119\n",
    "   - **Comments:** Validation accuracy improves significantly, but there is still a gap between training and validation accuracy.\n",
    "\n",
    "8. **Epoch 8:**\n",
    "   - **Training Accuracy:** 98.57%\n",
    "   - **Training Loss:** 0.0494\n",
    "   - **Validation Accuracy:** 85.00%\n",
    "   - **Validation Loss:** 1.6013\n",
    "   - **Comments:** Both training and validation accuracy continue to improve. The validation loss decreases substantially.\n",
    "\n",
    "9. **Epoch 9:**\n",
    "   - **Training Accuracy:** 98.57%\n",
    "   - **Training Loss:** 0.0491\n",
    "   - **Validation Accuracy:** 91.25%\n",
    "   - **Validation Loss:** 1.0496\n",
    "   - **Comments:** Significant improvement in both training and validation accuracy. The validation loss is relatively low.\n",
    "\n",
    "10. **Epoch 10:**\n",
    "   - **Training Accuracy:** 98.82%\n",
    "   - **Training Loss:** 0.0258\n",
    "   - **Validation Accuracy:** 48.75%\n",
    "   - **Validation Loss:** 7.7091\n",
    "   - **Comments:** There is a notable drop in validation accuracy, suggesting potential overfitting again. Validation loss is higher compared to the previous epochs.\n",
    "\n",
    "**Summary:**\n",
    "- The model initially struggled with overfitting, but there were improvements in generalization.\n",
    "- Fluctuations in validation accuracy and loss in later epochs indicate that further adjustments or regularization may be necessary to achieve better performance on unseen data. Validation Accuracy: 58.13%\n",
    "   - Validation Loss: 16.0212\n",
    "   - Comments: The model starts with relatively high training accuracy but struggles to generalize well on the validation set, indicating potential overfitting.\n",
    "\n",
    "2. Epoch 2:\n",
    "   - Training Accuracy: 98.15%\n",
    "   - Training Loss: 0.0590\n",
    "   - Validation Accuracy: 56.88%\n",
    "   - Validation Loss: 15.3434\n",
    "   - Comments: The training accuracy improves, but the validation accuracy decreases, suggesting that overfitting may still be an issue.\n",
    "\n",
    "3. Epoch 3:\n",
    "   - Training Accuracy: 98.32%\n",
    "   - Training Loss: 0.0439\n",
    "   - Validation Accuracy: 58.75%\n",
    "   - Validation Loss: 10.3247\n",
    "   - Comments: Both training and validation accuracies show improvement, indicating better generalization. However, the validation loss is still relatively high.\n",
    "\n",
    "4. Epoch 4:\n",
    "   - Training Accuracy: 98.91%\n",
    "   - Training Loss: 0.0374\n",
    "   - Validation Accuracy: 59.38%\n",
    "   - Validation Loss: 9.1711\n",
    "   - Comments: Continued improvement in training and validation accuracy, but the validation loss remains elevated.\n",
    "\n",
    "5. Epoch 5:\n",
    "   - Training Accuracy: 98.99%\n",
    "   - Training Loss: 0.0324\n",
    "   - Validation Accuracy: 71.25%\n",
    "   - Validation Loss: 3.1237\n",
    "   - Comments: Significant improvement in validation accuracy, indicating better generalization. The validation loss is also notably reduced.\n",
    "\n",
    "6. Epoch 6:\n",
    "   - Training Accuracy: 99.41%\n",
    "   - Training Loss: 0.0206\n",
    "   - Validation Accuracy: 57.50%\n",
    "   - Validation Loss: 11.4550\n",
    "   - Comments: Training accuracy remains high, but validation accuracy drops, suggesting potential overfitting again.\n",
    "\n",
    "7. Epoch 7:\n",
    "   - Training Accuracy: 98.03%\n",
    "   - Training Loss: 0.0581\n",
    "   - Validation Accuracy: 78.75%\n",
    "   - Validation Loss: 3.6119\n",
    "   - Comments: Validation accuracy improves significantly, but there is still a gap between training and validation accuracy.\n",
    "\n",
    "8. Epoch 8:\n",
    "   - Training Accuracy: 98.57%\n",
    "   - Training Loss: 0.0494\n",
    "   - Validation Accuracy: 85.00%\n",
    "   - Validation Loss: 1.6013\n",
    "   - Comments: Both training and validation accuracy continue to improve. The validation loss decreases substantially.\n",
    "\n",
    "9. Epoch 9:\n",
    "   - Training Accuracy: 98.57%\n",
    "   - Training Loss: 0.0491\n",
    "   - Validation Accuracy: 91.25%\n",
    "   - Validation Loss: 1.0496\n",
    "   - Comments: Significant improvement in both training and validation accuracy. The validation loss is relatively low.\n",
    "\n",
    "10. Epoch 10:\n",
    "   - Training Accuracy: 98.82%\n",
    "   - Training Loss: 0.0258\n",
    "   - Validation Accuracy: 48.75%\n",
    "   - Validation Loss: 7.7091\n",
    "   - Comments: There is a notable drop in validation accuracy, suggesting potential overfitting again. Validation loss is higher compared to the previous epochs.\n",
    "\n",
    "Summary:\n",
    "- The model initially struggled with overfitting, but there were improvements in generalization.\n",
    "- Fluctuations in validation accuracy and loss in later epochs indicate that further adjustments or regularization may be necessary to achieve better performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8196b6c5-94f1-4a89-8ce1-ab113d35fa69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
